\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{datetime}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
\begin{document}
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
library(randomForest)
library(caret)
library(doMC)
# set global chunk options
opts_chunk$set(fig.path='figure/', fig.align='center', fig.show='hold')
options(formatR.arrow=TRUE,width=90)
@

\date{\currenttime, \today}
\title{SmartFly: Train model and validate via cross-validation}
\author{Cindy Lamm}

\maketitle

Load prepared data from the previous step "Prepare Data For Modeling"
<<load-prepared-data>>=
rm(list=ls())   #clear memory
load("../02_prepare_data_for_modeling/rfModelData.RData")
@

Split the train data based on simple bootstrap resampling into a train and test set
<<split-train-data>>=
library(caret)
set.seed(998)
PERCENTAGE <- 0.03
inTraining <- createDataPartition(rfModelData$is_delayed, p=PERCENTAGE, list=FALSE) 
length(inTraining)
training <- rfModelData[inTraining,]
testing <- rfModelData[-inTraining,]
testing <- testing[1:100,] 
@

<<checkout-training-sample>>=
str(training)
@


Estimate a random forest using \Sexpr{PERCENTAGE*100}\% of the data - without crossvalidation:
<<estimate-single-random-forest>>=
library(randomForest)
delayRf <- randomForest(is_delayed ~ . - id, data=rfModelData, subset=inTraining, 
                        importance=TRUE, proximity=FALSE) 
@
% Note: On a Macbook with 16GB RAM it takes 
% \begin{itemize}
% \item 4 minutes for a training sample size of 1\% (about 76.000 obs)
% \item 6 minutes for a training sample size of 100.000 obs
% \item 30 minutes for a training sample size of 5\% (about 360.000 obs)
% \item 50 minutes for a training sample size of 7\% (about 510.000 obs).
% \end{itemize}


<<estimate-crossvalidate-random-forest, include=FALSE, eval=FALSE>>=
trainX <- training[!colnames(training) %in% "is_delayed"]
trainY <- as.factor(training$is_delayed)

library(doMC)
registerDoMC(cores = detectCores(all.tests=TRUE))
rm(rfModelData, inTraining)
set.seed(825)
delayRf <- train(x=trainX, y=trainY, method="rf",  
                 prox=TRUE, allowParallel=TRUE)
@

Check out the model result:
<<model-result>>=
delayRf
plot(delayRf)
@

<<do-evaluation>>=
testPrediction <- predict(delayRf, newdata=testing, type="prob")
classPrediction <- factor(ifelse(testPrediction$delayed<0.5,"on_time","delayed"), 
                          levels=c("on_time","delayed"))
confusionMatrix(classPrediction, reference=testing$is_delayed)
@


Save the model result:
<<save-model-result>>==
save(delayRf, trainX, trainY, testPrediction, file="../03_train_model/delayRf.RData")
@

\end{document}

% create the .tex with
% knit("../03_train_model/train_model.Rnw", output="../03_train_model/train_model.tex")