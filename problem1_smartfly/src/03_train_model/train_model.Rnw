\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{datetime}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
\begin{document}
<<setup, include=FALSE, cache=FALSE>>=
library(knitr)
library(randomForest)
library(caret)
# set global chunk options
opts_chunk$set(fig.path='figure/', fig.align='center', fig.show='hold')
options(formatR.arrow=TRUE,width=90)
@

\date{\currenttime, \today}
\title{SmartFly: Train model and validate via cross-validation}
\author{Cindy Lamm}

\maketitle

Load prepared data from the previous step "Prepare Data For Modeling"
<<load-prepared-data>>=
rm(list=ls())   #clear memory
load("../02_prepare_data_for_modeling/rfModelData.RData")
@

Split the train data based on simple bootstrap resampling into a series of train and test sets
<<split-train-data>>=
library(caret)
set.seed(998)
PERCENTAGE <- 0.07
inTraining <- createDataPartition(rfModelData$is_delayed, times=1, p = PERCENTAGE, list = FALSE) 
length(inTraining)
training <- rfModelData[inTraining,]
# testing  <- rfModelData[-inTraining,]
@

<<checkout-training-sample>>=
str(training)
@


Estimate a random forest using \Sexpr{PERCENTAGE*100}\% of the data - without crossvalidation:
<<estimate-single-random-forest>>=
library(randomForest)
delayRf <- randomForest(is_delayed ~ . - id, data=rfModelData, subset=inTraining, 
                        importance=TRUE, proximity=FALSE) 
@
Note: On a Macbook with 16GB RAM it takes 
\begin{itemize}
\item 4 minutes for a training sample size of 1\% (about 76.000 obs)
\item 6 minutes for a training sample size of 100.000 obs
\item 30 minutes for a training sample size of 5\% (about 360.000 obs)
\item 50 minutes for a training sample size of 7\% (about 510.000 obs).
\end{itemize}

% Estimate a random forest with 3-fold crossvalidation: % kills Macbook with 16GB RAM
<<estimate-crossvalidate-random-forest, include=FALSE, eval=FALSE>>=
delayRf <- train(is_delayed ~ ., data=training, method="rf", 
                 trControl=trainControl(method="cv",number=3), 
                 prox=TRUE, allowParallel=TRUE)
print(rf_model)
@



Check out the model result:
<<model-result>>=
delayRf
plot(delayRf)
@

Save the model result:
<<save-model-result>>==
save(delayRf, inTraining, file="../03_train_model/delayRf.RData")
@

\end{document}

% create the .tex with
% knit("../03_train_model/train_model.Rnw", output="../03_train_model/train_model.tex")