\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\usepackage{fullpage}
\usepackage{pdflscape}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{datetime}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
\begin{document}
\flushbottom

<<setup, include=FALSE, cache=FALSE>>=
rm(list=ls())   #clear memory
library(knitr)
library(plyr)
library(doMC)
# set global chunk options
opts_chunk$set(fig.path='figure/', fig.align='center', fig.show='hold')
options(formatR.arrow=TRUE,width=90)
@

\date{\currenttime, \today}
\title{Almost Famous}
\author{Cindy Lamm}

\maketitle

% ------------------------
% ------------------------ define functions
% ------------------------

<<define-seed, include=FALSE>>=
set.seed(748)
@


<<define-view-example, include=FALSE>>=
viewExample <- function(df,type) {
  nbEntriesPerVisit <- ifelse(type=="web",2,4)
  visitsFreq <- table(df$visit_id)
  exampleVisits <- which(visitsFreq==nbEntriesPerVisit)
  randIdx <- sample(1:length(exampleVisits),1)
  theOneExample <- exampleVisits[randIdx]
  df[df$visit_id==names(theOneExample),]  
}
@

<<define-aggregate-visits, include=FALSE>>=
aggregatePerVisit <- function(df) {
   aggVisit <- ddply(df, .(visit_id), summarise,
                      nb_entries=length(visit_id),
                      uid=unique(uid),
                      campaign=unique(campaign[!is.na(campaign)]),
                      nb_experiments=unique(experiments[!is.na(experiments)]),
                      actions=paste(action, collapse=","),
                      queries=unique(query[!is.na(query)]), 
                      median_time_diff=median(time_diff, na.rm=TRUE))  
   # note: query is only defined if action==landed
   aggVisit$actions <- as.factor(aggVisit$actions)
   aggVisit$queries <- as.factor(aggVisit$queries)
   return(aggVisit)
}
@

<<define-aggregate-uid, include=FALSE>>=
aggregatePerUid <- function(df) {
  aggUid <- ddply(df, .(uid), summarise,
                  nb_entries=length(uid),
                  visit_ids=paste(unique(visit_id), collapse=","),
                  campaign=paste(unique(campaign[!is.na(campaign)]), collapse=","),
                  nb_experiments=unique(experiments[!is.na(experiments)]),
                  actions=paste(action, collapse=","),
                  queries=paste(unique(query[!is.na(query)]), collapse=","),
                  median_time_diff=median(time_diff, na.rm=TRUE))  
  aggUid$visit_ids <- as.factor(aggUid$visit_ids)
  aggUid$campaign <- as.factor(aggUid$campaign)
  aggUid$actions <- as.factor(aggUid$actions)
  aggUid$queries <- as.factor(aggUid$queries)
  return(aggUid)
}
@

<<define-view-aggregated-example, include=FALSE>>=
viewAggExample <- function(df,isWeb,isUid) {
  nbEntriesPerVisit <- ifelse(isWeb=="web",2,4)
  if (isUid=="uid") nbEntriesPerVisit <- 2*nbEntriesPerVisit
  exampleVisits <- which(df$nb_entries==nbEntriesPerVisit)
  randIdx <- sample(1:length(exampleVisits),1)
  theOneExample <- exampleVisits[randIdx]
  df[theOneExample,]  
}
@

<<define-write-level-table, include=FALSE>>=
writeLevelMappingToFile <- function(df, variable, file) {
  varIdx <- which(names(df)==variable)  
  tmp <- unclass(unique(df[,varIdx]))
  mapping <- data.frame(numericLevel=tmp, characterLevel=levels(tmp))
  write.csv(mapping, file=file, row.names=FALSE)
}
@

<<defined-get-map-file-name, include=FALSE>>=
getMapFileName <- function(variableName, type) {
  paste("out/visits/",type,"_level_map_",variableName,".csv", sep="")
}
@

% ------------------------
% ------------------------ web analysis starts here
% ------------------------

\section{Complete Web Data}

Load variable names and types:
<<load-meta-data>>=
nameTypeDataFile  <- "../../data/raw_variables.csv"
variableNames <- read.csv(nameTypeDataFile, header=TRUE, stringsAsFactors=FALSE) 
variableNames
factorIdx <- which(variableNames$type=="factor")
factorNames <- variableNames$name[factorIdx]
@

Read the complete web.log data:
<<read-web-data>>=
webFile <- "../../data/web.csv"
webData <- read.csv(webFile, stringsAsFactors=FALSE, col.names=variableNames$name, 
                    colClasses=variableNames$type, na.strings=c("NA",""))
webData$tstamp <- as.POSIXct(webData$tstamp)
str(webData)
@

\pagebreak

Look at a summary for the complete web data:
<<summary-web-data>>=
summary(webData)
@

\section{Reduced Web Data}

Now reduce the web log data to the top 2000 entries just to get an impression.
<<reduce-web-data>>=
rm(webData)
webFile <- "../../data/head2000.csv"
webData <- read.csv(webFile, stringsAsFactors=FALSE, col.names=variableNames$name, 
                    colClasses=variableNames$type, na.strings=c("NA",""))
webData$tstamp <- as.POSIXct(webData$tstamp)
str(webData)
@

\textbf{Caution:} Running the following analysis with all web.log data locally will kill the Mac!
Add variable with the total time spent per visit, \verb+total_time_spent+, and \verb+time_diff+ indicating the seconds that passed inbetween the logged entries within a visit:
<<add-total-time-spent-to-web-data>>=
require(plyr)
library(doMC)
registerDoMC(cores=detectCores())
webData <- ddply(webData, .(visit_id), mutate, 
                 total_time_spent=max(tstamp)-min(tstamp),
                 time_diff=c(NA,diff(tstamp)), 
                 .parallel=TRUE)
viewExample(webData,"web")
@

Look at a summary per visit for the web data:
<<per-visit-summary-web>>=
webAggVisits <- aggregatePerVisit(webData)
summary(webAggVisits)
viewAggExample(webAggVisits, "web", "visit")
@

Look at a summary per uid (supposedly user) for the web data:
<<per-uid-summary-web>>=
webAggUids <- aggregatePerUid(webData)
summary(webAggUids)
viewAggExample(webAggUids, "web", "uid")
@

<<remove-webdata, include=FALSE>>=

@


% ------------------------
% ------------------------ spam analysis starts here
% ------------------------
\section{Spam Data}

Read spam data:
<<read-spam-data>>=
spamFile <- "../../data/spam.csv"
spamData <- read.csv(spamFile, stringsAsFactors=FALSE, col.names=variableNames$name, 
                     colClasses=variableNames$type, na.strings=c("NA",""))
spamData$tstamp <- as.POSIXct(spamData$tstamp)
str(spamData)
@

I again add a variable \verb+time_spent+ and
<<add-total-time-spent-to-spam-data, include=FALSE>>=
spamData <- ddply(spamData, .(visit_id), mutate, 
                  total_time_spent=max(tstamp)-min(tstamp),
                  time_diff=c(NA,diff(tstamp)))

viewExample(spamData,"spam")
@
look at a summary of the spam data:
<<summary-spam-data>>=
summary(spamData)
@

Look at a summary per visit for the spam data:
<<per-visit-summary-spam>>=
spamAggVisits <- aggregatePerVisit(spamData)
summary(spamAggVisits)
viewAggExample(spamAggVisits, "spam", "visit")
@

Look at a summary per uid (supposedly user) for the spam data:
<<per-uid-summary-spam>>=
spamAggUids <- aggregatePerUid(spamData)
summary(spamAggUids)
viewAggExample(spamAggUids, "spam", "uid")
@

Write out a file which can be processed by Spark, meaning all factors as numeric values. Also \verb+unclass+ factors with digits as levels to have resulting variables on roughly the same scale:
<<write-spam-numeric>>=
numericSpamVisits <- data.frame(visit_id=spamAggVisits$visit_id,
                                nb_actions=spamAggVisits$nb_entries,
                                uid=unclass(spamAggVisits$uid),
                                campaign=unclass(spamAggVisits$campaign), 
                                actions=unclass(spamAggVisits$actions),
                                queries=unclass(spamAggVisits$queries),
                                median_time_diff=spamAggVisits$median_time_diff)
head(numericSpamVisits)
write.csv(numericSpamVisits, file="out/visits/spam_visits_numeric.csv", row.names=FALSE)
@

Also write the level mapping in to files:
<<write-spam-level-mapping>>=
writeLevelMappingToFile(spamAggVisits, "uid", getMapFileName("uid","spam"))
writeLevelMappingToFile(spamAggVisits, "campaign", getMapFileName("campaign","spam"))
writeLevelMappingToFile(spamAggVisits, "actions", getMapFileName("actions","spam"))
writeLevelMappingToFile(spamAggVisits, "queries", getMapFileName("queries","spam"))
@

\end{document}

% create the .tex with 
% library(knitr)
% knit("read_data.Rnw", output="read_data.tex")